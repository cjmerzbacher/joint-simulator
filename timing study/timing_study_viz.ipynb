{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing Study Visualization - for Supplementary Figure S1\n",
    "Run the cells below in Julia 1.8 unless otherwise stated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports completed\n"
     ]
    }
   ],
   "source": [
    "home_path = \"C:/Users/Charlotte/OneDrive - University of Edinburgh/Documents/research/joint-simulator/\"\n",
    "\n",
    "include(home_path * \"models/glucaric_acid.jl\")\n",
    "\n",
    "# Import required package\n",
    "using DifferentialEquations\n",
    "using COBREXA\n",
    "using DataFrames\n",
    "using Tulip\n",
    "using Plots\n",
    "using Colors\n",
    "using ModelingToolkit\n",
    "using Statistics\n",
    "using GLM\n",
    "using Random\n",
    "using Flux\n",
    "using ProgressMeter\n",
    "using MLBase #Confusion matrix function\n",
    "using Serialization\n",
    "using TreeParzen\n",
    "using CSV\n",
    "using LatinHypercubeSampling\n",
    "println(\"Imports completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying flux feasibility...\n",
      "Accuracy on training set: 1.0\n",
      "Accuracy on test set: 1.0\n",
      "Predicting pathway influx...\n",
      "Final training loss: 7.55173370696956e-5\n",
      "Test loss: 6.900496302228796e-5\n",
      "Predicting growth rate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Layer with Float32 parameters got Float64 input.\n",
      "│   The input will be converted, but any earlier layers may be very slow.\n",
      "│   layer = Dense(1 => 500, relu)\n",
      "│   summary(x) = 1×367 adjoint(::Vector{Float64}) with eltype Float64\n",
      "└ @ Flux C:\\Users\\Charlotte\\.julia\\packages\\Flux\\uCLgc\\src\\layers\\stateless.jl:50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on training set: 2.6507269936868316e-32\n",
      "Model R^2: 0.9999940868993147\n",
      "MSE on test set: 9.814562595894043e-9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(StatsModels.TableRegressionModel{GeneralizedLinearModel{GLM.GlmResp{Vector{Float64}, Binomial{Float64}, LogitLink}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}, Vector{Int64}}}}, Matrix{Float64}}\n",
       "\n",
       "feas ~ 1 + v_dp\n",
       "\n",
       "Coefficients:\n",
       "─────────────────────────────────────────────────────────────────────────\n",
       "                Coef.  Std. Error      z  Pr(>|z|)   Lower 95%  Upper 95%\n",
       "─────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)  14701.9    1.24908e6   0.01    0.9906  -2.43344e6  2.46284e6\n",
       "v_dp         -1610.58   1.36827e5  -0.01    0.9906  -2.69787e5  2.66566e5\n",
       "─────────────────────────────────────────────────────────────────────────, Chain(Dense(1 => 500, relu), Dense(500 => 500, relu), Dense(500 => 1)), StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}, Vector{Int64}}}}, Matrix{Float64}}\n",
       "\n",
       "lam ~ 1 + v_dp\n",
       "\n",
       "Coefficients:\n",
       "───────────────────────────────────────────────────────────────────────────────\n",
       "                  Coef.  Std. Error         t  Pr(>|t|)   Lower 95%   Upper 95%\n",
       "───────────────────────────────────────────────────────────────────────────────\n",
       "(Intercept)   0.878573   6.56016e-5  13392.54    <1e-99   0.878444    0.878702\n",
       "v_dp         -0.0960157  1.22209e-5  -7856.65    <1e-99  -0.0960397  -0.0959917\n",
       "───────────────────────────────────────────────────────────────────────────────)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Load in standard training data:\n",
    "data = CSV.read(\"F:/medium_conditions/training_glucose.csv\", DataFrame)\n",
    "\n",
    "#Train ML models to predict feasibility\n",
    "replace!(data.v_in, NaN => -1)\n",
    "replace!(data.lam, NaN => -1)\n",
    "\n",
    "#Separate data into training and test\n",
    "Random.seed!(2023)\n",
    "train_indices = randsubseq(1:size(data, 1), 0.8)\n",
    "test_indices = setdiff(1:size(data, 1), train_indices)\n",
    "\n",
    "train_data = data[train_indices, :]\n",
    "test_data = data[test_indices, :]\n",
    "\n",
    "#Train a logistic regression model\n",
    "println(\"Classifying flux feasibility...\")\n",
    "feas_model = glm(@formula(feas~v_dp), train_data, Binomial(), LogitLink())\n",
    "\n",
    "#Compute training accuracy\n",
    "train_pred = predict(feas_model, train_data)\n",
    "train_pred_class = ifelse.(train_pred .> 0.5, 1, 0)\n",
    "accuracy = sum(train_pred_class .== train_data.feas) / length(train_data.feas)\n",
    "println(\"Accuracy on training set: $accuracy\")\n",
    "\n",
    "#Generate predictions on test set \n",
    "test_pred = predict(feas_model, test_data)\n",
    "test_pred_class = ifelse.(test_pred .> 0.5, 1, 0)\n",
    "accuracy = sum(test_pred_class .== test_data.feas) / length(test_data.feas)\n",
    "println(\"Accuracy on test set: $accuracy\")\n",
    "\n",
    "#Create and plot confusion matrix\n",
    "cm = confusmat(2, train_data.feas.+ 1, train_pred_class.+ 1)\n",
    "p1 = heatmap(cm, c=:blues, xlabel=\"Predicted\", ylabel=\"True\", title=\"Training Set\", xticks=nothing, yticks=nothing, colorbar=false, legend=nothing)\n",
    "annotate!([(i, j, text(cm[i, j])) for i in 1:size(cm)[1] for j in 1:size(cm)[2]])\n",
    "\n",
    "cm = confusmat(2, test_data.feas.+ 1, test_pred_class.+ 1)\n",
    "p2 = heatmap(cm, c=:blues, xlabel=\"Predicted\", ylabel=\"True\", title=\"Test Set\", xticks=nothing, yticks=nothing, colorbar=false, legend=nothing)\n",
    "annotate!([(i, j, text(cm[i, j])) for i in 1:size(cm)[1] for j in 1:size(cm)[2]])\n",
    "\n",
    "plot(p1, p2, layout = (1, 2), dpi=300, size=(400, 220))\n",
    "\n",
    "#Select only feasible data \n",
    "feas_train_indices = [findall(x -> x == 1, train_data.feas)] \n",
    "feas_train_data = train_data[feas_train_indices[1], :]\n",
    "feas_test_indices = [findall(x -> x == 1, test_pred_class)] \n",
    "feas_test_data = test_data[feas_test_indices[1], :]\n",
    "\n",
    "#Train a neural network model to predict v_in\n",
    "println(\"Predicting pathway influx...\")\n",
    "num_epochs = 1000\n",
    "step_size = 0.01\n",
    "num_units = 500\n",
    "#Create model architecture\n",
    "v_in_model = Chain(Dense(1, num_units, relu), Dense(num_units, num_units, relu), Dense(num_units, 1))\n",
    "\n",
    "#Transpose train and test data from DataFrame\n",
    "x_train = feas_train_data.v_dp'\n",
    "y_train = feas_train_data.v_in'\n",
    "x_test = feas_test_data.v_dp'\n",
    "y_test = feas_test_data.v_in'\n",
    "\n",
    "#Define loss function and optimizer\n",
    "loss(v_in_model, x, y) = mean(abs2.(v_in_model(x) .- y))\n",
    "opt = Flux.setup(Adam(step_size), v_in_model)\n",
    "\n",
    "#training loop\n",
    "losses = []\n",
    "for epoch in 1:num_epochs\n",
    "    Flux.train!(loss, v_in_model, [(x_train, y_train)], opt)\n",
    "    push!(losses, loss(v_in_model, x_train, y_train))\n",
    "end\n",
    "\n",
    "#Compute training loss\n",
    "train_loss = losses[end]\n",
    "println(\"Final training loss: $train_loss\")\n",
    "\n",
    "#Compute test loss\n",
    "test_loss = loss(v_in_model, x_test, y_test)\n",
    "println(\"Test loss: $test_loss\")\n",
    "\n",
    "#Train a linear model to predict lam\n",
    "println(\"Predicting growth rate...\")\n",
    "lam_model = fit(LinearModel, @formula(lam~v_dp), feas_train_data)\n",
    "\n",
    "#Compute training accuracy\n",
    "train_pred = predict(lam_model, feas_train_data)\n",
    "mse = (mean(feas_train_data.lam - train_pred).^2)\n",
    "r2_model = r2(lam_model)\n",
    "println(\"MSE on training set: $mse\")\n",
    "println(\"Model R^2: $r2_model\")\n",
    "\n",
    "#Compute test accuracy\n",
    "test_pred = predict(lam_model, feas_test_data)\n",
    "mse = (mean(feas_test_data.lam - test_pred).^2)\n",
    "println(\"MSE on test set: $mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"c:\\\\Users\\\\Charlotte\\\\OneDrive - University of Edinburgh\\\\Documents\\\\research\\\\joint-simulator\\\\figs\\\\lam_ground_truth_s1.png\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#FIGURE S1 - Machine learning results\n",
    "\n",
    "#CONFUSION MATRIX\n",
    "p1 = heatmap(cm, type=\"heatmap\", color =:blues, xticks=[], yticks=[], xlabel=\"Predicted Label\", ylabel=\"True Label\", aspect_ratio=:equal, legend=:none, dpi=300)\n",
    "#Annotate with numbers\n",
    "for i in 1:size(cm, 1)\n",
    "    for j in 1:size(cm, 2)\n",
    "        annotate!(j, i, text(cm[i, j], :center, 10))\n",
    "    end\n",
    "end\n",
    "plot(p1, layout=(1,1), size=(300,300))\n",
    "savefig(\"../figs/confusion_matrix.png\")\n",
    "\n",
    "#LOSS PLOT\n",
    "p2 = plot(losses, legend=:none, lw=3, xlabel=\"Neural Network\\nTraining Epoch\", ylabel=\"Log Loss\", dpi=300)\n",
    "\n",
    "plot(p2, layout=(1,1), size=(300,300))\n",
    "savefig(\"../figs/loss_plot_s1.png\")\n",
    "\n",
    "#GROUND TRUTH VS PREDICTION - v_in\n",
    "flux_data = DataFrame(\"v_dp\" => feas_train_data.v_dp[1:25:end])\n",
    "pred_v_in = v_in_model(flux_data.v_dp')\n",
    "\n",
    "p3 = plot(feas_train_data.v_dp, feas_train_data.v_in, legend=:none, lw=3, xlabel=\"Dynamic Pathway Flux (mM)\", ylabel=\"Boundary Influx (mM)\", dpi=300)\n",
    "scatter!(feas_train_data.v_dp[1:25:end], pred_v_in', legend=:none)\n",
    "\n",
    "plot(p3, layout=(1,1), size=(300,300))\n",
    "savefig(\"../figs/v_in_ground_truth_s1.png\")\n",
    "\n",
    "#GROUND TRUTH VS PREDICTION - lam\n",
    "p4 = plot(feas_train_data.v_dp, feas_train_data.lam, legend=:none, lw=3, xlabel=\"Dynamic Pathway Flux (mM)\", ylabel=\"Growth Rate(mM)\", dpi=300)\n",
    "scatter!(feas_train_data.v_dp[1:50:end], train_pred[1:50:end], legend=:none)\n",
    "\n",
    "plot(p4, layout=(1,1), size=(300,300))\n",
    "savefig(\"../figs/lam_ground_truth_s1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>5×3 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">time</th><th style = \"text-align: left;\">standard</th><th style = \"text-align: left;\">surrogate</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">5.9797</td><td style = \"text-align: right;\">0.21405</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">100</td><td style = \"text-align: right;\">31.231</td><td style = \"text-align: right;\">0.524416</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">1000</td><td style = \"text-align: right;\">279.028</td><td style = \"text-align: right;\">3.21071</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">3600</td><td style = \"text-align: right;\">1022.37</td><td style = \"text-align: right;\">11.054</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">36000</td><td style = \"text-align: right;\">10220.0</td><td style = \"text-align: right;\">120.788</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& time & standard & surrogate\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 10 & 5.9797 & 0.21405 \\\\\n",
       "\t2 & 100 & 31.231 & 0.524416 \\\\\n",
       "\t3 & 1000 & 279.028 & 3.21071 \\\\\n",
       "\t4 & 3600 & 1022.37 & 11.054 \\\\\n",
       "\t5 & 36000 & 10220.0 & 120.788 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×3 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m time  \u001b[0m\u001b[1m standard   \u001b[0m\u001b[1m surrogate  \u001b[0m\n",
       "     │\u001b[90m Int64 \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Float64    \u001b[0m\n",
       "─────┼───────────────────────────────\n",
       "   1 │    10      5.9797    0.21405\n",
       "   2 │   100     31.231     0.524416\n",
       "   3 │  1000    279.028     3.21071\n",
       "   4 │  3600   1022.37     11.054\n",
       "   5 │ 36000  10220.0     120.788"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# FIGURE S2 - Timing study results - taken from table\n",
    "timing = DataFrame(\"time\"=> [10, 100, 1000, 3600, 36000], \"standard\" => [5.979702, 31.231, 279.028147, 1022.374149 , 1022*10], \"surrogate\" => [0.21405, 0.5244158, 3.21071, 11.0540, 120.788])\n",
    "\n",
    "p = plot(timing.time, [timing.standard, timing.surrogate], lw=3, labels=[\"Standard Model\" \"ML Surrogate\"], xlabel=\"Number of Loop Iterations\", ylabel=\"Run Time (seconds)\", dpi=300)\n",
    "plot(p, size=(500, 300))\n",
    "savefig(\"../figs/suppfig2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
